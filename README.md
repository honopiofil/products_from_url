## General project structure
The project consists of three main modules:
- tagger which is used to prepare training and test sets
- a procedure for finetune'ing the Bert model using the set generated by the tagger
- model inference program


## Usage
1. Prepare environoment:
   
  (All modulles were tested with Python in version 3.8)
```
pip install -r requirements.txt
```


2. Prepare train and test set
```
python3 ./tagger.py <input_stores_urls_list> <output_annotated_phrases> <output_url_product_list>
```
where:
- `<input_stores_urls_list>` is provided CSV file with furniture online stores urls
- `<output_annotated_phrases>` is `HF Dataset`'s formatted list of phrases, where every line has a following structure:
```
phraseID,"['word0', 'word1', 'word2', 'word3', 'word4']","['tag0', 'tag1', 'tag2', 'tag3', 'tag4']"
```
`phraseID` consists of URL and phrase number as url_phraseno

`'tag...'` can be one of two values: `'00'` denotes no-product word and `'pp'` denotes product name

- `<output_url_product_list>`is CSV file with all responding URL's and product found there using tagger strategy

The most important idea of searching for products on the websites can be set using the logic defined in the `config/tagger.ini` file.


3. Train (fine-tune) model
Jupyter notebook file with step-by-step model training procedure. Local computer usage:
```
jupyter notebook fine-tune_Bert.ipynb
```
and follow the instructions.

All training parameters could be set in notebook.


4. Local inference
```
python inference_with_gradio.py <model_path>
```
and follow the instructions.

By default, program makes use of finetuned model which was uploaded to:
https://huggingface.co/honopiofil/bert_for_products


## Online inference
To check model online in inference mode see:
https://huggingface.co/spaces/honopiofil/furnitures_from_url
