{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4237c290",
   "metadata": {},
   "source": [
    "### Install necessary packages, prepare basic configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bfebdf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T22:25:26.501292278Z",
     "start_time": "2024-01-18T22:25:09.659549880Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./venv/lib/python3.7/site-packages (22.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m12.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.3.1\n",
      "    Uninstalling pip-22.3.1:\n",
      "      Successfully uninstalled pip-22.3.1\n",
      "Successfully installed pip-23.3.2\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl.metadata (113 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m113.6/113.6 kB\u001B[0m \u001B[31m1.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hCollecting datasets\n",
      "  Downloading datasets-2.13.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.12.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m15.7/15.7 MB\u001B[0m \u001B[31m49.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: packaging>=20.0 in ./venv/lib/python3.7/site-packages (from transformers) (23.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2023.12.25-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.9/40.9 kB\u001B[0m \u001B[31m8.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting requests (from transformers)\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.8/7.8 MB\u001B[0m \u001B[31m43.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0mm\n",
      "\u001B[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.6/57.6 kB\u001B[0m \u001B[31m10.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: importlib-metadata in ./venv/lib/python3.7/site-packages (from transformers) (6.7.0)\n",
      "Collecting pyarrow>=8.0.0 (from datasets)\n",
      "  Downloading pyarrow-12.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m110.5/110.5 kB\u001B[0m \u001B[31m17.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pandas (from datasets)\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.3/11.3 MB\u001B[0m \u001B[31m57.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hCollecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.15-py37-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2021.11.1 (from fsspec[http]>=2021.11.1->datasets)\n",
      "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m143.0/143.0 kB\u001B[0m \u001B[31m26.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.8.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting responses<0.19 (from evaluate)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.7/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Collecting charset-normalizer<4.0,>=2.0 (from aiohttp->datasets)\n",
      "  Downloading charset_normalizer-3.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m94.8/94.8 kB\u001B[0m \u001B[31m18.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m148.0/148.0 kB\u001B[0m \u001B[31m27.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting asynctest==0.13.0 (from aiohttp->datasets)\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in ./venv/lib/python3.7/site-packages (from aiohttp->datasets) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.7/site-packages (from requests->transformers) (3.6)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Downloading urllib3-2.0.7-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Downloading certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.15.0)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m115.7/115.7 kB\u001B[0m \u001B[31m21.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: python-dateutil>=2.7.3 in ./venv/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting pytz>=2017.3 (from pandas->datasets)\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.2/7.2 MB\u001B[0m \u001B[31m61.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading datasets-2.13.2-py3-none-any.whl (512 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m512.7/512.7 kB\u001B[0m \u001B[31m52.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m84.1/84.1 kB\u001B[0m \u001B[31m16.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading aiohttp-3.8.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (987 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m988.0/988.0 kB\u001B[0m \u001B[31m77.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m268.8/268.8 kB\u001B[0m \u001B[31m42.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pyarrow-12.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m39.1/39.1 MB\u001B[0m \u001B[31m37.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading PyYAML-6.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (670 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m670.1/670.1 kB\u001B[0m \u001B[31m67.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading regex-2023.12.25-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (761 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m761.6/761.6 kB\u001B[0m \u001B[31m57.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.6/62.6 kB\u001B[0m \u001B[31m15.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading safetensors-0.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m71.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.3/78.3 kB\u001B[0m \u001B[31m14.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Downloading xxhash-3.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m194.6/194.6 kB\u001B[0m \u001B[31m31.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m162.5/162.5 kB\u001B[0m \u001B[31m29.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading charset_normalizer-3.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m136.8/136.8 kB\u001B[0m \u001B[31m23.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m502.5/502.5 kB\u001B[0m \u001B[31m65.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m124.2/124.2 kB\u001B[0m \u001B[31m22.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading yarl-1.9.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (289 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m289.8/289.8 kB\u001B[0m \u001B[31m41.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: tokenizers, pytz, xxhash, urllib3, tqdm, safetensors, regex, pyyaml, numpy, multidict, fsspec, frozenlist, filelock, dill, charset-normalizer, certifi, asynctest, async-timeout, yarl, requests, pyarrow, pandas, multiprocess, aiosignal, responses, huggingface-hub, aiohttp, transformers, datasets, evaluate\n",
      "Successfully installed aiohttp-3.8.6 aiosignal-1.3.1 async-timeout-4.0.3 asynctest-0.13.0 certifi-2023.11.17 charset-normalizer-3.3.2 datasets-2.13.2 dill-0.3.6 evaluate-0.4.1 filelock-3.12.2 frozenlist-1.3.3 fsspec-2023.1.0 huggingface-hub-0.16.4 multidict-6.0.4 multiprocess-0.70.14 numpy-1.21.6 pandas-1.3.5 pyarrow-12.0.1 pytz-2023.3.post1 pyyaml-6.0.1 regex-2023.12.25 requests-2.31.0 responses-0.18.0 safetensors-0.4.1 tokenizers-0.13.3 tqdm-4.66.1 transformers-4.30.2 urllib3-2.0.7 xxhash-3.4.1 yarl-1.9.4\n",
      "Collecting seqeval\n",
      "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.14.0 in ./venv/lib/python3.7/site-packages (from seqeval) (1.21.6)\n",
      "Collecting scikit-learn>=0.21.3 (from seqeval)\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.8/24.8 MB\u001B[0m \u001B[31m44.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hCollecting scipy>=1.1.0 (from scikit-learn>=0.21.3->seqeval)\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m38.1/38.1 MB\u001B[0m \u001B[31m37.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hCollecting joblib>=0.11 (from scikit-learn>=0.21.3->seqeval)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.21.3->seqeval)\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m302.2/302.2 kB\u001B[0m \u001B[31m45.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: threadpoolctl, scipy, joblib, scikit-learn, seqeval\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.0.2 scipy-1.7.3 seqeval-1.2.2 threadpoolctl-3.1.0\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.0/6.0 MB\u001B[0m \u001B[31m22.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hCollecting absl-py>=0.4 (from tensorboard)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.24.3 (from tensorboard)\n",
      "  Downloading grpcio-1.60.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard)\n",
      "  Downloading google_auth-2.26.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard)\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in ./venv/lib/python3.7/site-packages (from tensorboard) (1.21.6)\n",
      "Collecting protobuf<4,>=3.9.2 (from tensorboard)\n",
      "  Downloading protobuf-3.20.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m24.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.7/site-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./venv/lib/python3.7/site-packages (from tensorboard) (65.5.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.9/4.9 MB\u001B[0m \u001B[31m64.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard)\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m781.3/781.3 kB\u001B[0m \u001B[31m63.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m233.6/233.6 kB\u001B[0m \u001B[31m40.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: wheel>=0.26 in ./venv/lib/python3.7/site-packages (from tensorboard) (0.38.4)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard)\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m181.3/181.3 kB\u001B[0m \u001B[31m25.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./venv/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard) (6.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2023.11.17)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in ./venv/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.7.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard)\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m151.7/151.7 kB\u001B[0m \u001B[31m24.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m133.7/133.7 kB\u001B[0m \u001B[31m26.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading google_auth-2.26.2-py2.py3-none-any.whl (186 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m186.5/186.5 kB\u001B[0m \u001B[31m30.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading grpcio-1.60.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.4/5.4 MB\u001B[0m \u001B[31m63.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m94.2/94.2 kB\u001B[0m \u001B[31m20.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m84.9/84.9 kB\u001B[0m \u001B[31m15.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: tensorboard-plugin-wit, werkzeug, tensorboard-data-server, pyasn1, protobuf, oauthlib, grpcio, cachetools, absl-py, rsa, requests-oauthlib, pyasn1-modules, markdown, google-auth, google-auth-oauthlib, tensorboard\n",
      "Successfully installed absl-py-2.1.0 cachetools-5.3.2 google-auth-2.26.2 google-auth-oauthlib-0.4.6 grpcio-1.60.0 markdown-3.4.4 oauthlib-3.2.2 protobuf-3.20.3 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.2.3\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./venv/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./venv/lib/python3.7/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./venv/lib/python3.7/site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m887.5/887.5 MB\u001B[0m \u001B[31m3.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions in ./venv/lib/python3.7/site-packages (from torch) (4.7.1)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m849.3/849.3 kB\u001B[0m \u001B[31m79.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch)\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m557.1/557.1 MB\u001B[0m \u001B[31m4.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch)\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m317.1/317.1 MB\u001B[0m \u001B[31m6.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.0/21.0 MB\u001B[0m \u001B[31m56.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: setuptools in ./venv/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
      "Requirement already satisfied: wheel in ./venv/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
      "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n",
      "Requirement already satisfied: transformers[torch] in ./venv/lib/python3.7/site-packages (4.30.2)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.7/site-packages (from transformers[torch]) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in ./venv/lib/python3.7/site-packages (from transformers[torch]) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.7/site-packages (from transformers[torch]) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.7/site-packages (from transformers[torch]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.7/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.7/site-packages (from transformers[torch]) (2023.12.25)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.7/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./venv/lib/python3.7/site-packages (from transformers[torch]) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.7/site-packages (from transformers[torch]) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.7/site-packages (from transformers[torch]) (4.66.1)\n",
      "Requirement already satisfied: importlib-metadata in ./venv/lib/python3.7/site-packages (from transformers[torch]) (6.7.0)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.9 in ./venv/lib/python3.7/site-packages (from transformers[torch]) (1.13.1)\n",
      "Collecting accelerate>=0.20.2 (from transformers[torch])\n",
      "  Downloading accelerate-0.20.3-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.7/site-packages (from accelerate>=0.20.2->transformers[torch]) (5.9.7)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./venv/lib/python3.7/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./venv/lib/python3.7/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./venv/lib/python3.7/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./venv/lib/python3.7/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.7.99)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.9->transformers[torch]) (65.5.1)\n",
      "Requirement already satisfied: wheel in ./venv/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.9->transformers[torch]) (0.38.4)\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.7/site-packages (from importlib-metadata->transformers[torch]) (3.15.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.7/site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.7/site-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.7/site-packages (from requests->transformers[torch]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.7/site-packages (from requests->transformers[torch]) (2023.11.17)\n",
      "Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m227.6/227.6 kB\u001B[0m \u001B[31m3.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: accelerate\n",
      "Successfully installed accelerate-0.20.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install transformers datasets evaluate\n",
    "# !pip install seqeval\n",
    "# !pip install tensorboard\n",
    "# !pip install pandas\n",
    "# !pip install torch\n",
    "# !pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c17152",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:08:02.949433714Z",
     "start_time": "2024-01-23T00:08:01.179281046Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ff9d9b",
   "metadata": {},
   "source": [
    "### Load train and test sets into dataframes\n",
    "- load the training and test collections separately, because the test collection is reviewed for correct annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9c2cb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:08:04.440884764Z",
     "start_time": "2024-01-23T00:08:04.290086071Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_csv = 'url_prods_train_set_small2.csv'\n",
    "test_data_csv = 'url_prods_test_set.csv'\n",
    "\n",
    "def read_data(file_name):\n",
    "    from ast import literal_eval\n",
    "    dataset_df = pd.read_csv(file_name)\n",
    "    dataset_df.columns = ['id', 'tokens', 'ner_tags']\n",
    "    # .apply(literal_eval) applied to the DF column allows to convert strings of type [\"el0\", \"el1\"]\n",
    "    # into appropriate structures (e.g. lists in this case)\n",
    "    dataset_df.tokens = dataset_df.tokens.apply(literal_eval)\n",
    "    dataset_df.ner_tags = dataset_df.ner_tags.apply(literal_eval)\n",
    "    return dataset_df\n",
    "\n",
    "trainset_df = read_data(train_data_csv)\n",
    "testset_df = read_data(test_data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd17bfd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:08:05.076876094Z",
     "start_time": "2024-01-23T00:08:05.044872133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2523 entries, 0 to 2522\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        2523 non-null   object\n",
      " 1   tokens    2523 non-null   object\n",
      " 2   ner_tags  2523 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 59.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36 entries, 0 to 35\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        36 non-null     object\n",
      " 1   tokens    36 non-null     object\n",
      " 2   ner_tags  36 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 992.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "trainset_df.info()\n",
    "testset_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a05f73b",
   "metadata": {},
   "source": [
    "### Convert dataframes into HF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53d6dcd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:08:07.069921233Z",
     "start_time": "2024-01-23T00:08:06.627121999Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "def get_Dataset(trainset_df, testset_df):\n",
    "    dataset = DatasetDict({\n",
    "        'train': Dataset.from_pandas(trainset_df),\n",
    "        'test': Dataset.from_pandas(testset_df)\n",
    "    })\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56842d7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:08:07.790699325Z",
     "start_time": "2024-01-23T00:08:07.751512244Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = get_Dataset(trainset_df, testset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da4ed764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:08:08.246329149Z",
     "start_time": "2024-01-23T00:08:08.214693557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': 'https://www.royaloakfurniture.co.uk/products/pop-bench_22',\n 'tokens': ['All', 'items'],\n 'ner_tags': ['00', '00']}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965b8f62",
   "metadata": {},
   "source": [
    "### Prepare appropriate dictionaries for NER classes\n",
    "- method is universal - it catches tags automatically and allows additional classes to be handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c386a1a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:08:13.483965699Z",
     "start_time": "2024-01-23T00:08:13.453255763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'00': 0, 'pp': 1}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = pd.concat([trainset_df, testset_df])\n",
    "\n",
    "tags_lists = [el for el in dataset_df.ner_tags]\n",
    "label_list = list(set([item for sublist in tags_lists for item in sublist]))\n",
    "\n",
    "# we want the empty tag '00' to be a 0-indexed element\n",
    "label_list.remove('00')\n",
    "label_list.insert(0, '00')\n",
    "\n",
    "label_encoding_dict = {v: n for n, v in enumerate(label_list)}\n",
    "encoding_label_dict = {v: n for n, v in label_encoding_dict.items()}\n",
    "label_encoding_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06805adb",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f3cb1d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:08:19.950469920Z",
     "start_time": "2024-01-23T00:08:19.804703882Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "def get_tokenizer(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "592bcf92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:08:28.748502552Z",
     "start_time": "2024-01-23T00:08:28.734671721Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tokenized_ds(ds, tokenizer):\n",
    "    def tokenize_and_align_labels(examples):\n",
    "        label_all_tokens = True\n",
    "        # in the following key are parameters that cause truncation of long examples max_length=512, truncation=True\n",
    "        # - without them, errors appeared in training\n",
    "        tokenized_inputs = tokenizer(list(examples[\"tokens\"]), max_length=512, truncation=True,\n",
    "                                     is_split_into_words=True)\n",
    "\n",
    "        labels = []\n",
    "        for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "            word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "            previous_word_idx = None\n",
    "            label_ids = []\n",
    "            for word_idx in word_ids:\n",
    "                if word_idx is None:\n",
    "                    label_ids.append(-100)\n",
    "                elif label[word_idx] == '0':\n",
    "                    label_ids.append(0)\n",
    "                elif word_idx != previous_word_idx:\n",
    "                    label_ids.append(label_encoding_dict[label[word_idx]])\n",
    "                else:\n",
    "                    label_ids.append(label_encoding_dict[label[word_idx]] if label_all_tokens else -100)\n",
    "                previous_word_idx = word_idx\n",
    "            labels.append(label_ids)\n",
    "\n",
    "        tokenized_inputs[\"labels\"] = labels\n",
    "        return tokenized_inputs\n",
    "\n",
    "    tokenized_ds = ds.map(tokenize_and_align_labels, batched=True)\n",
    "    return tokenized_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b21d06d",
   "metadata": {},
   "source": [
    "### `data_collator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27fb52d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:08:33.879830254Z",
     "start_time": "2024-01-23T00:08:33.422878993Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "def get_collator(tokenizer):\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "    return data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bac4775",
   "metadata": {},
   "source": [
    "### `TrainingArguments`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6e03a29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:08:36.589423972Z",
     "start_time": "2024-01-23T00:08:36.176451271Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "def get_args(out_dir):\n",
    "    batch_size = 6\n",
    "    args = TrainingArguments(\n",
    "        out_dir,\n",
    "        learning_rate=1e-6,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=20,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        metric_for_best_model=\"f1\",\n",
    "        save_total_limit=1,\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=False,\n",
    "        report_to=\"tensorboard\"\n",
    "    )\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8355efbe",
   "metadata": {},
   "source": [
    "### Definition of metrics for the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad100ac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:08:42.822716959Z",
     "start_time": "2024-01-23T00:08:41.445780734Z"
    }
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a22527",
   "metadata": {},
   "source": [
    "### Load base Bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97159fe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:08:46.276569037Z",
     "start_time": "2024-01-23T00:08:46.262273736Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "def get_model(model_name):\n",
    "    # because of different set of ner tags one needs to use the parameter ignore_mismatched_sizes=True:\n",
    "    # https://stackoverflow.com/questions/69194640/mismatched-size-on-bertforsequenceclassification-from-transformers-and-multiclas\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(encoding_label_dict), id2label=encoding_label_dict, label2id=label_encoding_dict, ignore_mismatched_sizes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5253d609",
   "metadata": {},
   "source": [
    "### Prepare `Trainer` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8903e17f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:08:56.932692289Z",
     "start_time": "2024-01-23T00:08:56.895688306Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "def do_training(args, tokenizer, model, data_collator, tokenized_ds):\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=tokenized_ds[\"train\"],\n",
    "        eval_dataset=tokenized_ds[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67a21bd",
   "metadata": {},
   "source": [
    "### Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efdcbaa9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-18T22:30:39.629807876Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dslim/bert-base-NER and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2523 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizerFast(name_or_path='dslim/bert-base-NER', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)\n",
      "BertTokenizerFast(name_or_path='dslim/bert-base-NER', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)\n",
      "BertTokenizerFast(name_or_path='dslim/bert-base-NER', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizerFast(name_or_path='dslim/bert-base-NER', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/transformers/optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2820' max='2820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2820/2820 13:55, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.488226</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.817102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.407816</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.845606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.355461</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.455446</td>\n",
       "      <td>0.869359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.352800</td>\n",
       "      <td>0.302850</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.556701</td>\n",
       "      <td>0.909739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.352800</td>\n",
       "      <td>0.270923</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.921615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.352800</td>\n",
       "      <td>0.242225</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.703297</td>\n",
       "      <td>0.933492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.352800</td>\n",
       "      <td>0.221074</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.935867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.214600</td>\n",
       "      <td>0.201253</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.942993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.214600</td>\n",
       "      <td>0.183886</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.947743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.214600</td>\n",
       "      <td>0.170374</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.703297</td>\n",
       "      <td>0.954869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.158762</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.959620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.151783</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.959620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.149734</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.961995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.140630</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.969121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.133200</td>\n",
       "      <td>0.136804</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.969121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.133200</td>\n",
       "      <td>0.133390</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.971496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.133200</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.969121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.130536</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.969121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.129811</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.966746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.129375</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.966746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 00 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/pawel/ner_products/venv/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: pp seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    }
   ],
   "source": [
    "out_dirs = [f\"FT_url_prods_bert-base-NER\"]\n",
    "\n",
    "models = [\"dslim/bert-base-NER\"]\n",
    "\n",
    "for out_dir_name, model_name in zip(out_dirs, models):\n",
    "    args = get_args(out_dir_name)\n",
    "    tokenizer = get_tokenizer(model_name)\n",
    "    model = get_model(model_name)\n",
    "    data_collator = get_collator(tokenizer)\n",
    "    tokenized_ds = get_tokenized_ds(ds, tokenizer)\n",
    "    do_training(args, tokenizer, model, data_collator, tokenized_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77fec01",
   "metadata": {},
   "source": [
    "### Basic inference for made up examples\n",
    "- use of `aggregation_strategy='simple'`:\n",
    "https://stackoverflow.com/questions/63221913/named-entity-recognition-with-huggingface-transformers-mapping-back-to-complete?noredirect=1&lq=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8bafc28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:09:18.289508500Z",
     "start_time": "2024-01-23T00:09:18.244008925Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = [\"Alfi High Back Dining Chair\",\n",
    "        \"The Alfi High Back Armchair, a creation by the acclaimed designer Jasper Morrison, seamlessly combines aesthetic allure with environmental responsibility.\",\n",
    "        \"Crafted in the USA, it reflects a commitment to quality craftsmanship\",\n",
    "        \"Designed by Jasper Morrison\",\n",
    "        \"Founded in 2010 by Martin Kornbek Hansen, &Tradition has firmly positioned itself at the intersection of the past and the present.\",\n",
    "        \"Canadian Modern Lounge Chairs - 1519\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "887efcbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:09:22.580698745Z",
     "start_time": "2024-01-23T00:09:21.148613829Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('ner', model='FT_url_prods_bert-base-NER/checkpoint-2397/', aggregation_strategy='simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11c18cd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:09:25.013163541Z",
     "start_time": "2024-01-23T00:09:24.377719860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'pp', 'score': 0.9783449, 'word': 'Alfi High Back Dining Chair', 'start': 0, 'end': 27}]\n",
      "[{'entity_group': '00', 'score': 0.9781562, 'word': 'The', 'start': 0, 'end': 3}, {'entity_group': 'pp', 'score': 0.8243359, 'word': 'Alfi High Back Armchair', 'start': 4, 'end': 27}, {'entity_group': '00', 'score': 0.9623857, 'word': ', a creation by the acclaimed designer Jasper Morrison, seamlessly combines aesthetic allure with environmental responsibility.', 'start': 27, 'end': 154}]\n",
      "[{'entity_group': '00', 'score': 0.98863316, 'word': 'Crafted in the USA, it reflects a commitment to quality craftsmanship', 'start': 0, 'end': 69}]\n",
      "[{'entity_group': '00', 'score': 0.7393595, 'word': 'Designed by Jasper Morrison', 'start': 0, 'end': 27}]\n",
      "[{'entity_group': '00', 'score': 0.9564371, 'word': 'Founded in 2010 by Martin Kornbek Hansen, & Tradition has firmly positioned itself at the intersection of the past and the present.', 'start': 0, 'end': 130}]\n",
      "[{'entity_group': '00', 'score': 0.76040065, 'word': 'Canadian', 'start': 0, 'end': 8}, {'entity_group': 'pp', 'score': 0.60284096, 'word': 'Modern Lounge Chair', 'start': 9, 'end': 28}, {'entity_group': '00', 'score': 0.63655925, 'word': '##s - 1519', 'start': 28, 'end': 36}]\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    print(classifier(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4506982",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T00:09:29.440615359Z",
     "start_time": "2024-01-23T00:09:28.728758990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfi High Back Dining Chair\n",
      "Alfi High Back Armchair\n",
      "Modern Lounge Chair\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    for segment in classifier(text):\n",
    "        if segment['entity_group'] == 'pp':\n",
    "            print(segment['word'])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f8482f42a2743055"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
